{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Controller",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUQ3a6EEp6M-",
        "outputId": "dfceb389-2b35-4bfb-8de6-1d543e6a92b0"
      },
      "source": [
        "import torch\n",
        "print('Version', torch.__version__)\n",
        "print('CUDA enabled:', torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version 1.7.0+cu101\n",
            "CUDA enabled: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2HRhZevqKGM",
        "outputId": "663b2555-380b-4ca2-e0b9-6256c9f75c95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okFqoEYFqfVv"
      },
      "source": [
        "import os\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/Final Project/'\n",
        "os.chdir(BASE_PATH)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hZz6VBaemjq",
        "outputId": "fa570a17-0024-43af-ec6f-e7aab4f4fafa"
      },
      "source": [
        "!pip install gym[box2d]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.18.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.4.1)\n",
            "Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (2.3.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmHZGqOY-ISX",
        "outputId": "f909d3aa-2cef-48ca-87bc-060b924f5388"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.7.0+cu101)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.17.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.8.1+cu101)\n",
            "Requirement already satisfied: cma in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 3)) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8wQIc-WduRu"
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWFsLx81dihc"
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osfHTcqe9Vng"
      },
      "source": [
        "from utils import *\n",
        "from models import VAE, MDRNNCell, Controller"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDFxoeI_q13v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be29796e-fe76-403d-9256-85864db95442"
      },
      "source": [
        "import pyglet\n",
        "print(pyglet.version)\n",
        "import argparse\n",
        "import sys\n",
        "from os.path import join, exists, abspath\n",
        "from os import mkdir, unlink, listdir, getpid\n",
        "from time import sleep\n",
        "from torch.multiprocessing import Process, Queue\n",
        "import torch\n",
        "import cma\n",
        "from models import Controller\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from utils.misc import RolloutGenerator, ASIZE, RSIZE, LSIZE\n",
        "from utils.misc import load_parameters\n",
        "from utils.misc import flatten_parameters\n",
        "from torch.multiprocessing import Process, Queue\n",
        "import multiprocessing"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP32E_XwFINI"
      },
      "source": [
        "ASIZE, LSIZE, RSIZE, RED_SIZE, SIZE =\\\n",
        "    3, 32, 64, 64, 64"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE0LaKi5dmJJ"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "# This code creates a virtual display to draw game images on. \n",
        "# If you are running locally, just ignore it\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEGS9UiaslrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4444ca6a-03d8-4166-ac5c-270968bf7402"
      },
      "source": [
        "time_limit = 1000\n",
        "device = \"cuda\"\n",
        "pop_size = 4\n",
        "n_samples = 4\n",
        "target_return = 950\n",
        "display = True\n",
        "controller = Controller(LSIZE, RSIZE, ASIZE)\n",
        "parameters = controller.parameters()\n",
        "es = cma.CMAEvolutionStrategy(flatten_parameters(parameters), 0.1,\n",
        "                              {'popsize': pop_size})\n",
        "vae_weights_path = \"weights/vae_original.pt\"\n",
        "mdrnn_weights_path = \"weights/mdrnn.pt\"\n",
        "rg = RolloutGenerator(\"weights/vae_original.pt\", \"weights/mdrnn.pt\", device, time_limit)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2_w,4mirr1)-aCMA-ES (mu_w=1.5,w_1=80%) in dimension 291 (seed=876978, Sun Dec 13 01:59:41 2020)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct8ejkNXkdeT"
      },
      "source": [
        "from collections import deque\n",
        "p_queue = deque()\n",
        "r_queue = deque()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwPor6OhsI_t"
      },
      "source": [
        "def evaluate(solutions, results, rollouts=10):\n",
        "    \"\"\" Give current controller evaluation.\n",
        "    Evaluation is minus the cumulated reward averaged over rollout runs.\n",
        "    :args solutions: CMA set of solutions\n",
        "    :args results: corresponding results\n",
        "    :args rollouts: number of rollouts\n",
        "    :returns: minus averaged cumulated reward\n",
        "    \"\"\"\n",
        "    index_min = np.argmin(results)\n",
        "    best_guess = solutions[index_min]\n",
        "    restimates = []\n",
        "\n",
        "    for s_id in range(rollouts):\n",
        "        p_queue.append((s_id, best_guess))\n",
        "    \n",
        "    while  len(p_queue) != 0:\n",
        "      id, best_guess = p_queue.popleft()\n",
        "      r_queue.append((id, rg.rollout(best_guess)))\n",
        "\n",
        "    print(\"Evaluating...\")\n",
        "    for _ in tqdm(range(rollouts)):\n",
        "        restimates.append(r_queue.popleft()[1])\n",
        "\n",
        "    return best_guess, np.mean(restimates), np.std(restimates)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0IlONS2pVpR",
        "outputId": "85fec405-1ae9-496b-8f3f-9296c0a0c2d1"
      },
      "source": [
        "pop_size * n_samples"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfHKhH4t-6UP",
        "outputId": "e0b50ca1-d6ec-4408-ce50-9042dbfb198a"
      },
      "source": [
        "epoch = 0\n",
        "log_step = 3\n",
        "while epoch < 3:\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    if cur_best is not None and - cur_best > target_return:\n",
        "        print(\"Already better than target, breaking...\")\n",
        "        break\n",
        "\n",
        "    r_list = [0] * pop_size  # result list\n",
        "    solutions = es.ask()\n",
        "    print(f\"Number of solutions: {len(solutions)}\")\n",
        "    # push parameters to queue\n",
        "    for s_id, s in enumerate(solutions):\n",
        "        for _ in range(n_samples):\n",
        "            p_queue.append((s_id, s))\n",
        "    print(f\"Filled up p_queue of size {len(p_queue)}\")\n",
        "    count = 0\n",
        "    while len(p_queue) != 0:\n",
        "      if count % pop_size == 0:\n",
        "        print(count)\n",
        "      id, sol = p_queue.popleft()\n",
        "      r_queue.append((id, rg.rollout(sol)))\n",
        "      count += 1\n",
        "    print(f\"Filled up r_queue of size {len(r_queue)}\")\n",
        "    # retrieve results\n",
        "    if display:\n",
        "        pbar = tqdm(total=pop_size * n_samples)\n",
        "    for _ in range(pop_size * n_samples):\n",
        "        r_s_id, r = r_queue.popleft()\n",
        "        r_list[r_s_id] += r / n_samples\n",
        "        if display:\n",
        "            pbar.update(1)\n",
        "    print(\"Filled up r_list\")\n",
        "    if display:\n",
        "        pbar.close()\n",
        "\n",
        "    es.tell(solutions, r_list)\n",
        "    es.disp()\n",
        "\n",
        "    # evaluation and saving\n",
        "    if epoch % log_step == log_step - 1:\n",
        "        best_params, best, std_best = evaluate(solutions, r_list)\n",
        "        print(\"Current evaluation: {}\".format(best))\n",
        "        if not cur_best or cur_best > best:\n",
        "            cur_best = best\n",
        "            print(f\"New best is {cur_best}\")\n",
        "            # print(\"Saving new best with value {}+-{}...\".format(-cur_best, std_best))\n",
        "            # load_parameters(best_params, controller)\n",
        "            # torch.save(\n",
        "            #     {'epoch': epoch,\n",
        "            #      'reward': - cur_best,\n",
        "            #      'state_dict': controller.state_dict()},\n",
        "            #     join(ctrl_dir, 'best.tar'))\n",
        "        if - best > target_return:\n",
        "            print(\"Terminating controller training with value {}...\".format(best))\n",
        "            break\n",
        "    epoch += 1\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Number of solutions: 4\n",
            "Filled up p_queue of size 16\n",
            "0\n",
            "Track generation: 1199..1503 -> 304-tiles track\n",
            "Track generation: 1026..1287 -> 261-tiles track\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Track generation: 1196..1499 -> 303-tiles track\n",
            "Track generation: 1406..1762 -> 356-tiles track\n",
            "Track generation: 1361..1705 -> 344-tiles track\n",
            "4\n",
            "Track generation: 904..1138 -> 234-tiles track\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Track generation: 1252..1569 -> 317-tiles track\n",
            "Track generation: 1191..1493 -> 302-tiles track\n",
            "Track generation: 1112..1394 -> 282-tiles track\n",
            "Track generation: 1135..1423 -> 288-tiles track\n",
            "8\n",
            "Track generation: 1272..1593 -> 321-tiles track\n",
            "Track generation: 1119..1403 -> 284-tiles track\n",
            "Track generation: 1072..1344 -> 272-tiles track\n",
            "Track generation: 1153..1445 -> 292-tiles track\n",
            "12\n",
            "Track generation: 1176..1474 -> 298-tiles track\n",
            "Track generation: 1361..1705 -> 344-tiles track\n",
            "Track generation: 1095..1373 -> 278-tiles track\n",
            "Track generation: 1075..1347 -> 272-tiles track\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 37680.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Filled up r_queue of size 16\n",
            "Filled up r_list\n",
            "    4     16 8.276871009774811e+01 1.0e+00 9.48e-02  9e-02  9e-02 7:08.8\n",
            "Epoch: 1\n",
            "Number of solutions: 4\n",
            "Filled up p_queue of size 16\n",
            "0\n",
            "Track generation: 1190..1491 -> 301-tiles track\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Track generation: 1188..1489 -> 301-tiles track\n",
            "Track generation: 1065..1344 -> 279-tiles track\n",
            "Track generation: 1160..1464 -> 304-tiles track\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Track generation: 906..1143 -> 237-tiles track\n",
            "4\n",
            "Track generation: 1186..1488 -> 302-tiles track\n",
            "Track generation: 1185..1486 -> 301-tiles track\n",
            "Track generation: 1059..1328 -> 269-tiles track\n",
            "Track generation: 1013..1274 -> 261-tiles track\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Track generation: 1273..1595 -> 322-tiles track\n",
            "8\n",
            "Track generation: 906..1143 -> 237-tiles track\n",
            "Track generation: 1071..1343 -> 272-tiles track\n",
            "Track generation: 950..1197 -> 247-tiles track\n",
            "Track generation: 1089..1365 -> 276-tiles track\n",
            "12\n",
            "Track generation: 1034..1304 -> 270-tiles track\n",
            "Track generation: 1212..1526 -> 314-tiles track\n",
            "Track generation: 1205..1510 -> 305-tiles track\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaDltsOLwzhO",
        "outputId": "73c00278-3562-46c0-80e4-6fdbe21ef096"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec 13 02:10:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    23W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHLqa7jU3T_N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}